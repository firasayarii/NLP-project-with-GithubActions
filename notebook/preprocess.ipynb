{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vifMeyEClsib"
   },
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_09kvKKrY6A"
   },
   "source": [
    "We import the The Natural Language Toolkit (NLTK) library, which is widely used for natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EiqG4mdlbls",
    "outputId": "5cc59f1b-36da-42d6-c981-b8e627a66f56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpgYdsmmlmfb"
   },
   "source": [
    "# **Load the IMDB Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsvC0JrOreAn"
   },
   "source": [
    "We load the movie reviews dataset from NLTK. Each review is stored in a list, and we label them as positive (pos) or negative (neg) based on the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnfkqgTRllAD",
    "outputId": "5392a2b2-be99-43eb-b2f9-2213659f1f82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  plot : two teen couples go to a church party ,...       neg\n",
       "1  the happy bastard's quick movie review \\ndamn ...       neg\n",
       "2  it is movies like these that make a jaded movi...       neg\n",
       "3   \" quest for camelot \" is warner bros . ' firs...       neg\n",
       "4  synopsis : a mentally unstable man undergoing ...       neg"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Load the dataset\n",
    "reviews = []\n",
    "labels = []\n",
    "\n",
    "# Extract reviews and their corresponding sentiments (pos/neg)\n",
    "for fileid in movie_reviews.fileids():\n",
    "    reviews.append(movie_reviews.raw(fileid))\n",
    "    labels.append(fileid.split('/')[0])  # 'pos' or 'neg' is part of the file name\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'review': reviews,\n",
    "    'sentiment': labels\n",
    "})\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neg    1000\n",
       "pos    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4n_ww-Tmuxc"
   },
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jlea3Glnrkv2"
   },
   "source": [
    "Converting all text to lowercase to ensure uniformity and reduce the complexity of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyRlc_Y_llQD",
    "outputId": "e1d7fb12-c463-4a24-9869-06f30f1188ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couples go to a church party dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>the happy bastards quick movie review damn tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest for camelot is warner bros first featur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  plot : two teen couples go to a church party ,...   \n",
       "1  the happy bastard's quick movie review \\ndamn ...   \n",
       "2  it is movies like these that make a jaded movi...   \n",
       "3   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  plot two teen couples go to a church party dri...  \n",
       "1  the happy bastards quick movie review damn tha...  \n",
       "2  it is movies like these that make a jaded movi...  \n",
       "3   quest for camelot is warner bros first featur...  \n",
       "4  synopsis a mentally unstable man undergoing ps...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "\n",
    "# Check the cleaned data\n",
    "df[['review', 'cleaned_review']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stopwords (except negations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Charger le modèle de langue anglais\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Récupérer la liste des stop words\n",
    "stop_words_spacy = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus    import stopwords\n",
    "stop_words_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the predefined STOPWORDS by Spacy , because it contains more words than NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot teen couples church party drink drive acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>happy bastards quick movie review damn yk bug ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>movies like jaded movie viewer thankful invent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest camelot warner bros featurelength fullya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis mentally unstable man undergoing psyc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  plot : two teen couples go to a church party ,...   \n",
       "1  the happy bastard's quick movie review \\ndamn ...   \n",
       "2  it is movies like these that make a jaded movi...   \n",
       "3   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  plot teen couples church party drink drive acc...  \n",
       "1  happy bastards quick movie review damn yk bug ...  \n",
       "2  movies like jaded movie viewer thankful invent...  \n",
       "3  quest camelot warner bros featurelength fullya...  \n",
       "4  synopsis mentally unstable man undergoing psyc...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = text.split() \n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words_spacy]  \n",
    "    return ' '.join(filtered_tokens)  \n",
    "\n",
    "df['cleaned_review'] = df['cleaned_review'].apply(remove_stopwords)\n",
    "\n",
    "df[['review', 'cleaned_review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL-a8Gb5nUG7"
   },
   "source": [
    "# **Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GBZdiyErpIf"
   },
   "source": [
    " This step splits the cleaned text into individual words (tokens). Tokenization is essential because it allows us to analyze the text at a granular level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRNC55Lsm5uT",
    "outputId": "1e38594d-edea-400e-ef53-990b54c6244f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:53<00:00, 37.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot teen couples church party drink drive acc...</td>\n",
       "      <td>[plot, teen, couples, church, party, drink, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy bastards quick movie review damn yk bug ...</td>\n",
       "      <td>[happy, bastards, quick, movie, review, damn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movies like jaded movie viewer thankful invent...</td>\n",
       "      <td>[movies, like, jaded, movie, viewer, thankful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quest camelot warner bros featurelength fullya...</td>\n",
       "      <td>[quest, camelot, warner, bros, featurelength, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis mentally unstable man undergoing psyc...</td>\n",
       "      <td>[synopsis, mentally, unstable, man, undergoing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_review  \\\n",
       "0  plot teen couples church party drink drive acc...   \n",
       "1  happy bastards quick movie review damn yk bug ...   \n",
       "2  movies like jaded movie viewer thankful invent...   \n",
       "3  quest camelot warner bros featurelength fullya...   \n",
       "4  synopsis mentally unstable man undergoing psyc...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [plot, teen, couples, church, party, drink, dr...  \n",
       "1  [happy, bastards, quick, movie, review, damn, ...  \n",
       "2  [movies, like, jaded, movie, viewer, thankful,...  \n",
       "3  [quest, camelot, warner, bros, featurelength, ...  \n",
       "4  [synopsis, mentally, unstable, man, undergoing...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "# Load the SpaCy language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function for tokenization\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "# Assume df is your DataFrame and has a 'cleaned_review' column\n",
    "# If you want to track progress in a Jupyter notebook, you can use tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply tokenization to cleaned reviews\n",
    "df['tokens'] = df['cleaned_review'].progress_apply(tokenize_text)\n",
    "\n",
    "# Check the tokenized data\n",
    "df[['cleaned_review', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot teen couples church party drink drive accident guys dies girlfriend continues life nightmares whats deal watch movie sorta find critique mindfuck movie teen generation touches cool idea presents bad package makes review harder write generally applaud films attempt break mold mess head lost highway memento good bad ways making types films folks didnt snag correctly taken pretty neat concept executed terribly problems movie main problem simply jumbled starts normal downshifts fantasy world audience member idea whats going dreams characters coming dead look like dead strange apparitions disappearances looooot chase scenes tons weird things happen simply explained personally dont mind trying unravel film clue kind fed films biggest problem obviously got big secret hide want hide completely final minutes things entertaining thrilling engaging meantime sad arrow dig flicks like actually figured halfway point strangeness start little bit sense didnt film entertaining guess line movies like sure audience given secret password enter world understanding mean showing melissa sagemiller running away visions minutes movie plain lazy okay people chasing dont know need giving different scenes offering insight strangeness going movie apparently studio took film away director chopped shows mightve pretty decent teen mindfuck movie guess suits decided turning music video little edge sense actors pretty good wes bentley playing exact character american beauty new neighborhood biggest kudos sagemiller holds entire film actually feeling characters unraveling overall film doesnt stick doesnt entertain confusing rarely excites feels pretty redundant runtime despite pretty cool ending explanation craziness came oh way horror teen slasher flick packaged look way apparently assuming genre hot kids wrapped production years ago sitting shelves skip wheres joblo coming nightmare elm street blair witch crow crow salvation lost highway memento stir echoes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cleaned_review.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "L6fJXVJsnHLB",
    "outputId": "fe44816b-214c-4825-d091-2dceb95045c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [plot, teen, couples, church, party, drink, dr...\n",
       "1    [happy, bastards, quick, movie, review, damn, ...\n",
       "2    [movies, like, jaded, movie, viewer, thankful,...\n",
       "3    [quest, camelot, warner, bros, featurelength, ...\n",
       "4    [synopsis, mentally, unstable, man, undergoing...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:07<00:00, 281.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot, teen, couples, church, party, drink, dr...</td>\n",
       "      <td>[plot, teen, coupl, church, parti, drink, driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[happy, bastards, quick, movie, review, damn, ...</td>\n",
       "      <td>[happi, bastard, quick, movi, review, damn, yk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[movies, like, jaded, movie, viewer, thankful,...</td>\n",
       "      <td>[movi, like, jade, movi, viewer, thank, invent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[quest, camelot, warner, bros, featurelength, ...</td>\n",
       "      <td>[quest, camelot, warner, bro, featurelength, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis, mentally, unstable, man, undergoing...</td>\n",
       "      <td>[synopsi, mental, unstabl, man, undergo, psych...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [plot, teen, couples, church, party, drink, dr...   \n",
       "1  [happy, bastards, quick, movie, review, damn, ...   \n",
       "2  [movies, like, jaded, movie, viewer, thankful,...   \n",
       "3  [quest, camelot, warner, bros, featurelength, ...   \n",
       "4  [synopsis, mentally, unstable, man, undergoing...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [plot, teen, coupl, church, parti, drink, driv...  \n",
       "1  [happi, bastard, quick, movi, review, damn, yk...  \n",
       "2  [movi, like, jade, movi, viewer, thank, invent...  \n",
       "3  [quest, camelot, warner, bro, featurelength, f...  \n",
       "4  [synopsi, mental, unstabl, man, undergo, psych...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm  \n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Apply stemming to the tokens\n",
    "df['stemmed_tokens'] = df['tokens'].progress_apply(stem_tokens)\n",
    "\n",
    "# Display the results\n",
    "df[['tokens', 'stemmed_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wb4dBVVOomCK"
   },
   "source": [
    "# **Lemmatization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGmU-t64sCTH"
   },
   "source": [
    "This step reduces words to their base form (lemma) while considering the context provided by the POS tag (e.g., \"running\" becomes \"run\"). This is more sophisticated than stemming because it aims for a proper dictionary form of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fi1ZTjuworUp",
    "outputId": "eb5a423e-be39-49f4-cf59-199b846a7140"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:49<00:00, 40.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  \\\n",
      "0  [plot, teen, couples, church, party, drink, dr...   \n",
      "1  [happy, bastards, quick, movie, review, damn, ...   \n",
      "2  [movies, like, jaded, movie, viewer, thankful,...   \n",
      "3  [quest, camelot, warner, bros, featurelength, ...   \n",
      "4  [synopsis, mentally, unstable, man, undergoing...   \n",
      "\n",
      "                                   lemmatized_tokens  \n",
      "0  [plot, teen, couple, church, party, drink, dri...  \n",
      "1  [happy, bastard, quick, movie, review, damn, y...  \n",
      "2  [movie, like, jade, movie, viewer, thankful, i...  \n",
      "3  [quest, camelot, warner, bros, featurelength, ...  \n",
      "4  [synopsis, mentally, unstable, man, undergo, p...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    doc = nlp(\" \".join(tokens))  \n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "# Apply lemmatization to the filtered tokens\n",
    "df['lemmatized_tokens'] = df['tokens'].progress_apply(lemmatize_tokens)\n",
    "\n",
    "print(df[['tokens', 'lemmatized_tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot, teen, couples, church, party, drink, dr...</td>\n",
       "      <td>[plot, teen, couple, church, party, drink, dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[happy, bastards, quick, movie, review, damn, ...</td>\n",
       "      <td>[happy, bastard, quick, movie, review, damn, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[movies, like, jaded, movie, viewer, thankful,...</td>\n",
       "      <td>[movie, like, jade, movie, viewer, thankful, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[quest, camelot, warner, bros, featurelength, ...</td>\n",
       "      <td>[quest, camelot, warner, bros, featurelength, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis, mentally, unstable, man, undergoing...</td>\n",
       "      <td>[synopsis, mentally, unstable, man, undergo, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [plot, teen, couples, church, party, drink, dr...   \n",
       "1  [happy, bastards, quick, movie, review, damn, ...   \n",
       "2  [movies, like, jaded, movie, viewer, thankful,...   \n",
       "3  [quest, camelot, warner, bros, featurelength, ...   \n",
       "4  [synopsis, mentally, unstable, man, undergoing...   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "0  [plot, teen, couple, church, party, drink, dri...  \n",
       "1  [happy, bastard, quick, movie, review, damn, y...  \n",
       "2  [movie, like, jade, movie, viewer, thankful, i...  \n",
       "3  [quest, camelot, warner, bros, featurelength, ...  \n",
       "4  [synopsis, mentally, unstable, man, undergo, p...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tokens', 'lemmatized_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sge3IjvBqaZR"
   },
   "source": [
    "# **POS Tagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbf2EGa2sNZG"
   },
   "source": [
    " This step assigns part-of-speech tags to the lemmatized tokens, providing information about the grammatical role of each word in the context of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:50<00:00, 39.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(plot, plot, NOUN), (teen, teen, NOUN), (coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(happy, happy, ADJ), (bastard, bastard, NOUN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(movie, movie, NOUN), (like, like, ADP), (jad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(quest, quest, PROPN), (camelot, camelot, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(synopsis, synopsis, NOUN), (mentally, mental...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pos_tags\n",
       "0  [(plot, plot, NOUN), (teen, teen, NOUN), (coup...\n",
       "1  [(happy, happy, ADJ), (bastard, bastard, NOUN)...\n",
       "2  [(movie, movie, NOUN), (like, like, ADP), (jad...\n",
       "3  [(quest, quest, PROPN), (camelot, camelot, PRO...\n",
       "4  [(synopsis, synopsis, NOUN), (mentally, mental..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_tagging(tokens):\n",
    "    doc = nlp(\" \".join(tokens))  # Join tokens back to string for processing\n",
    "    return [(token.text, token.lemma_, token.pos_) for token in doc]\n",
    "\n",
    "df['pos_tags'] = df['lemmatized_tokens'].progress_apply(pos_tagging)\n",
    "\n",
    "df[['pos_tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>filtered_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot, teen, couple, church, party, drink, dri...</td>\n",
       "      <td>[die, continue, nightmare, s, find, touch, coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[happy, bastard, quick, movie, review, damn, y...</td>\n",
       "      <td>[happy, quick, get, start, tugboat, come, dese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[movie, like, jade, movie, viewer, thankful, i...</td>\n",
       "      <td>[thankful, tell, employ, undercover, wrong, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[quest, camelot, warner, bros, featurelength, ...</td>\n",
       "      <td>[steal, recent, cast, colorful, beat, come, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis, mentally, unstable, man, undergo, p...</td>\n",
       "      <td>[unstable, undergo, fatal, attempt, gain, take...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   lemmatized_tokens  \\\n",
       "0  [plot, teen, couple, church, party, drink, dri...   \n",
       "1  [happy, bastard, quick, movie, review, damn, y...   \n",
       "2  [movie, like, jade, movie, viewer, thankful, i...   \n",
       "3  [quest, camelot, warner, bros, featurelength, ...   \n",
       "4  [synopsis, mentally, unstable, man, undergo, p...   \n",
       "\n",
       "                                     filtered_tokens  \n",
       "0  [die, continue, nightmare, s, find, touch, coo...  \n",
       "1  [happy, quick, get, start, tugboat, come, dese...  \n",
       "2  [thankful, tell, employ, undercover, wrong, st...  \n",
       "3  [steal, recent, cast, colorful, beat, come, go...  \n",
       "4  [unstable, undergo, fatal, attempt, gain, take...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_tagging_and_filter(tokens):\n",
    "    # Apply POS tagging\n",
    "    doc=nlp(' '.join(tokens))\n",
    "\n",
    "    # Filter only nouns and verbs\n",
    "    filtered_tokens = [token for token in doc if token.pos_ == 'NN' or token.pos_ == 'ADJ' or token.pos_ == 'VERB']\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply POS tagging and filtering to lemmatized tokens\n",
    "df['filtered_tokens'] = df['lemmatized_tokens'].apply(pos_tagging_and_filter)\n",
    "\n",
    "# Check the filtered data (verbs and nouns only)\n",
    "df[['lemmatized_tokens', 'filtered_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsIFjSShsoeW"
   },
   "source": [
    "# **Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIPMCc2us0KW"
   },
   "source": [
    "## **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(sequence):\n",
    "    s=[]\n",
    "    for token in sequence :\n",
    "        s.append(str(token))\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sentiment', 'filtered_text']].to_csv('data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxN-qyixs-Ee"
   },
   "source": [
    " We initialize the TfidfVectorizer from Scikit-learn and fit it to the cleaned reviews. TF-IDF is used to convert the text data into a numerical format, reflecting the importance of each term in the context of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "RpgB-woHspDm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df['filtered_text'] = df['filtered_tokens'].apply(filter_text)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for simplicity\n",
    "\n",
    "# Fit and transform the cleaned reviews\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['filtered_text'])\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hssn4E4nuaNE"
   },
   "source": [
    "## **FastText**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLCbktBtue6c"
   },
   "source": [
    "We prepare the data in a format suitable for FastText and train the FastText model. FastText considers subword information, making it effective for morphologically rich languages and out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>sentence_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>die continue nightmare s find touch cool prese...</td>\n",
       "      <td>[-0.1114065, -0.18956636, -0.013039182, -0.095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>happy quick get start tugboat come deserted ru...</td>\n",
       "      <td>[-0.11111246, -0.20685868, -0.01965093, -0.094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>thankful tell employ undercover wrong steal qu...</td>\n",
       "      <td>[-0.11836663, -0.18973967, -0.0038995314, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>steal recent cast colorful beat come good dead...</td>\n",
       "      <td>[-0.11764066, -0.18240635, -0.0067705964, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>unstable undergo fatal attempt gain take kill ...</td>\n",
       "      <td>[-0.11568695, -0.17534785, -0.004221192, -0.09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                      filtered_text  \\\n",
       "0       neg  die continue nightmare s find touch cool prese...   \n",
       "1       neg  happy quick get start tugboat come deserted ru...   \n",
       "2       neg  thankful tell employ undercover wrong steal qu...   \n",
       "3       neg  steal recent cast colorful beat come good dead...   \n",
       "4       neg  unstable undergo fatal attempt gain take kill ...   \n",
       "\n",
       "                                  sentence_embedding  \n",
       "0  [-0.1114065, -0.18956636, -0.013039182, -0.095...  \n",
       "1  [-0.11111246, -0.20685868, -0.01965093, -0.094...  \n",
       "2  [-0.11836663, -0.18973967, -0.0038995314, -0.1...  \n",
       "3  [-0.11764066, -0.18240635, -0.0067705964, -0.0...  \n",
       "4  [-0.11568695, -0.17534785, -0.004221192, -0.09...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('data/preprocessed_data.csv',index_col=0)\n",
    "df['filtered_text'].to_csv('corpus.txt',header=False)\n",
    "# Entraînement d'un modèle FastText sur votre propre corpus\n",
    "fasttext_model = fasttext.train_unsupervised('corpus.txt', model='skipgram')\n",
    "\n",
    "# Fonction pour obtenir l'embedding d'une phrase\n",
    "def get_sentence_embedding(sentence, model):\n",
    "    words = sentence.split()  # Tokenisation simple\n",
    "    word_vectors = [fasttext_model.get_word_vector(word) for word in words if word in fasttext_model]\n",
    "    \n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(fasttext_model.get_dimension())  # Retourner un vecteur nul si aucun mot n'est trouvé\n",
    "    return np.mean(word_vectors, axis=0)  # Moyenne des embeddings pour la phrase\n",
    "\n",
    "# Charger votre DataFrame (assurez-vous que 'filtered_text' est la colonne de texte)\n",
    "\n",
    "\n",
    "# Calculer les embeddings de chaque phrase et les ajouter comme une nouvelle colonne\n",
    "df['sentence_embedding'] = df['filtered_text'].apply(lambda x: get_sentence_embedding(x, fasttext_model))\n",
    "\n",
    "# Exemple de contenu du DataFrame après l'ajout de l'embedding\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBERT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle SBERT\n",
    "embedding = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SBERT'] = df['filtered_text'].apply(lambda x: embedding.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>sentence_embedding</th>\n",
       "      <th>SBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>die continue nightmare s find touch cool prese...</td>\n",
       "      <td>[-0.1114065, -0.18956636, -0.013039182, -0.095...</td>\n",
       "      <td>[0.021407606, -0.084070146, 0.060046904, 0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>happy quick get start tugboat come deserted ru...</td>\n",
       "      <td>[-0.11111246, -0.20685868, -0.01965093, -0.094...</td>\n",
       "      <td>[-0.05555948, -0.028392768, 0.05569559, 0.0244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>thankful tell employ undercover wrong steal qu...</td>\n",
       "      <td>[-0.11836663, -0.18973967, -0.0038995314, -0.1...</td>\n",
       "      <td>[-0.0770346, -0.01919024, 0.06839841, -0.02606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>steal recent cast colorful beat come good dead...</td>\n",
       "      <td>[-0.11764066, -0.18240635, -0.0067705964, -0.0...</td>\n",
       "      <td>[-0.06858337, -0.016195001, 0.02190971, -0.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>unstable undergo fatal attempt gain take kill ...</td>\n",
       "      <td>[-0.11568695, -0.17534785, -0.004221192, -0.09...</td>\n",
       "      <td>[0.055572182, -0.052183226, -0.0023587106, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                      filtered_text  \\\n",
       "0       neg  die continue nightmare s find touch cool prese...   \n",
       "1       neg  happy quick get start tugboat come deserted ru...   \n",
       "2       neg  thankful tell employ undercover wrong steal qu...   \n",
       "3       neg  steal recent cast colorful beat come good dead...   \n",
       "4       neg  unstable undergo fatal attempt gain take kill ...   \n",
       "\n",
       "                                  sentence_embedding  \\\n",
       "0  [-0.1114065, -0.18956636, -0.013039182, -0.095...   \n",
       "1  [-0.11111246, -0.20685868, -0.01965093, -0.094...   \n",
       "2  [-0.11836663, -0.18973967, -0.0038995314, -0.1...   \n",
       "3  [-0.11764066, -0.18240635, -0.0067705964, -0.0...   \n",
       "4  [-0.11568695, -0.17534785, -0.004221192, -0.09...   \n",
       "\n",
       "                                               SBERT  \n",
       "0  [0.021407606, -0.084070146, 0.060046904, 0.001...  \n",
       "1  [-0.05555948, -0.028392768, 0.05569559, 0.0244...  \n",
       "2  [-0.0770346, -0.01919024, 0.06839841, -0.02606...  \n",
       "3  [-0.06858337, -0.016195001, 0.02190971, -0.050...  \n",
       "4  [0.055572182, -0.052183226, -0.0023587106, -0....  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43QTXw8MbkJY"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "BgxDJ7LQybhp"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# TF-IDF feature matrix\n",
    "X_tfidf = tfidf_matrix\n",
    "X_fasttext = np.array(df['sentence_embedding'].tolist())\n",
    "X_SBERT = np.array(df['SBERT'].tolist())\n",
    "y = label_encoder.fit_transform(df['sentiment'])  # Assuming 'label' contains the sentiment (0 or 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ1195pAzkIX"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "# Evaluate each feature extraction method\n",
    "results = {}\n",
    "\n",
    "# TF-IDF\n",
    "results['TF-IDF'] = train_and_evaluate(X_tfidf, y)\n",
    "\n",
    "results['SBERT'] = train_and_evaluate(X_SBERT, y)\n",
    "\n",
    "\n",
    "# FastText\n",
    "results['FastText'] = train_and_evaluate(X_fasttext, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozzD6kUszrlQ",
    "outputId": "c8fb6885-a251-4aec-de8b-9fb817d14aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: TF-IDF\n",
      "Accuracy: 0.8125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       199\n",
      "           1       0.80      0.83      0.82       201\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.81      0.81       400\n",
      "weighted avg       0.81      0.81      0.81       400\n",
      "\n",
      "\n",
      "Method: SBERT\n",
      "Accuracy: 0.7225\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       199\n",
      "           1       0.71      0.75      0.73       201\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.72      0.72      0.72       400\n",
      "weighted avg       0.72      0.72      0.72       400\n",
      "\n",
      "\n",
      "Method: FastText\n",
      "Accuracy: 0.63\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       199\n",
      "           1       0.63      0.63      0.63       201\n",
      "\n",
      "    accuracy                           0.63       400\n",
      "   macro avg       0.63      0.63      0.63       400\n",
      "weighted avg       0.63      0.63      0.63       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method, (accuracy, report) in results.items():\n",
    "    print(f\"Method: {method}\\nAccuracy: {accuracy}\\nClassification Report:\\n{report}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "1ya9rW_dzu3o",
    "outputId": "6f126528-7576-4a43-e209-8a7d3b26037c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAIjCAYAAACH9WOrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBV0lEQVR4nO3de3zP9f//8ft759mJzcaWtY3lkCEROZRIEZHSiWRyKKeEDnT4GKX0kaSI4iP66KSiEwtNVjmUDnxKaeWYlEhsy2HH5++Pfnt9e9uwzQ7P6Xa9XN6XvJ/v5+v1erxee77f7b7X6/V8u4wxRgAAAACASuVR2QUAAAAAAAhnAAAAAGAFwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAUEFcLpcmTpxY2WWcsUWLFqlhw4by9vZW9erVK7ucElu4cKFcLpd27dpV2aU4XC6XRo4cWe7bSU1NlcvlUmpq6mn7XnbZZbrsssuc57t27ZLL5dLChQvLrT4bDBgwQIGBgWW6zokTJ8rlcpXpOgGcnQhnACrM9u3bdccdd6hu3bry8/NTcHCw2rVrp6efflrHjh2r7PJQDN9//70GDBigevXqad68eZo7d26R/aZOnSqXy6VNmza5tRtjVKNGDblcLu3cudPttePHj8vX11d9+/Ytt/pLouAX6pM99u3bV9kl/iPExsae8udQ8DjbQyOAfwavyi4AwD/D8uXLdcMNN8jX11f9+/dXQkKCsrOztXbtWt1777369ttvT/qL/tni2LFj8vKq2h+7qampys/P19NPP634+PiT9mvfvr0kae3atWrevLnT/u233+rw4cPy8vLSunXrFBcX57z2+eefKzs721nWFnPmzCnyTEpVPGt4JmJiYnTs2DF5e3tX6HZnzJihP//803menJysV199VU899ZRq1qzptLdt27ZC6yqJhx56SOPHj6/sMgBUAVX7twQAVcLOnTt18803KyYmRh9++KEiIyOd10aMGKFt27Zp+fLllVhh+cnPz1d2drb8/Pzk5+dX2eWcsf3790s6fTBp2bKl/Pz8tHbtWt15551O+7p16xQWFqaWLVtq7dq16tevn/Pa2rVrJemMw9nfj3lZuP76691CwD+Vy+WqlDHcq1cvt+f79u3Tq6++ql69eik2NrbC6ykNLy+vKv+HGQAVg8saAZS7qVOn6s8//9T8+fPdglmB+Ph43XXXXc7z3NxcPfLII6pXr558fX0VGxurBx54QFlZWW7LxcbG6uqrr1Zqaqpatmwpf39/NWnSxLmfZunSpWrSpIn8/PzUokWLQpfYFdxbsmPHDnXp0kUBAQGKiorSww8/LGOMW99p06apbdu2CgsLk7+/v1q0aKE333yz0L4U3Dv08ssvq3HjxvL19dWKFSuc1/5+z1lmZqZGjx6t2NhY+fr6KiIiQldccYW++uort3W+8cYbatGihfz9/VWzZk3169dPe/fuLXJf9u7dq169eikwMFDh4eG65557lJeXd5KfjLvZs2c7NUdFRWnEiBE6fPiw2/FOSkqSJIWHh5/yHjofHx9ddNFFWrdunVv7unXr1KZNG7Vr167I16pXr66EhARJ0pEjR3T33XcrOjpavr6+atCggaZNm1boZ3OqY/7tt9+qU6dO8vf3V506dTR58mTl5+cX63gUV8F9XK+//romTZqkc845R0FBQbr++uuVnp6urKwsjR49WhEREQoMDNRtt91WaCwXePnll9WgQQNnzH788ceF+uzdu1cDBw5UrVq15Ovrq8aNG+uFF14o1O/nn39Wr169FBAQoIiICI0ZM+ak2507d67q1asnf39/tWrVSp988kmhPkXdc1aScXfw4EHdeuutCg4OVvXq1ZWYmKj//e9/ZXZJ4ksvveS8T0JDQ3XzzTdrz549hfp99tln6tatm2rUqKGAgAA1bdpUTz/9dKF+p9unguMxbdo05/j5+vrqoosu0ueff+62rqLuOcvKytKYMWMUHh6uoKAg9ezZUz///HOh99WAAQOKDKEnu4+tOMfhxx9/VO/evVW7dm35+fmpTp06uvnmm5Wenl7ksQVQcfgzDoBy995776lu3brFvuxo8ODBevHFF3X99dfr7rvv1meffaYpU6Zo69ateuutt9z6btu2TX379tUdd9yhfv36adq0aerRo4eee+45PfDAAxo+fLgkacqUKbrxxhuVlpYmD4//+7tUXl6eunbtqosvvlhTp07VihUrlJSUpNzcXD388MNOv6efflo9e/bULbfcouzsbL322mu64YYbtGzZMnXv3t2tpg8//FCvv/66Ro4cqZo1a570r/tDhw7Vm2++qZEjR+r888/XwYMHtXbtWm3dulUXXnihpL8mr7jtttt00UUXacqUKfrtt9/09NNPa926ddq0aZPbGay8vDx16dJFrVu31rRp05SSkqInn3xS9erV07Bhw055zCdOnKhJkyapc+fOGjZsmNLS0jRnzhx9/vnnWrdunby9vTVjxgz997//1VtvveVc6te0adOTrrN9+/b65JNPtGvXLucYrFu3ToMHD1arVq2UlJSkw4cPq3r16jLGaP369WrTpo08PDxkjFHPnj21Zs0aDRo0SBdccIFWrlype++9V3v37tVTTz112mO+b98+dezYUbm5uRo/frwCAgI0d+5c+fv7n/JYnOiPP/4o1Obl5VXo7OGUKVPk7++v8ePHa9u2bZo5c6a8vb3l4eGhQ4cOaeLEifr000+1cOFCxcXFacKECW7Lf/TRR1q8eLFGjRolX19fzZ49W127dtXGjRudwPrbb7/p4osvdgJpeHi43n//fQ0aNEgZGRkaPXq0pL8uob388sv1008/adSoUYqKitKiRYv04YcfFtqX+fPn64477lDbtm01evRo7dixQz179lRoaKiio6NPe3yKM+7y8/PVo0cPbdy4UcOGDVPDhg31zjvvKDExsTg/gtN69NFH9a9//Us33nijBg8erAMHDmjmzJm69NJL3d4nH3zwga6++mpFRkbqrrvuUu3atbV161YtW7bM7Q9EJXkvvfLKK8rMzNQdd9whl8ulqVOn6rrrrtOOHTtOeQno4MGD9dJLL6lv375q27atPvzww0KfJeVxHLKzs9WlSxdlZWXpzjvvVO3atbV3714tW7ZMhw8fVkhIyBnVAOAMGQAoR+np6UaSueaaa4rVf/PmzUaSGTx4sFv7PffcYySZDz/80GmLiYkxksz69eudtpUrVxpJxt/f3+zevdtpf/75540ks2bNGqctMTHRSDJ33nmn05afn2+6d+9ufHx8zIEDB5z2o0ePutWTnZ1tEhISTKdOndzaJRkPDw/z7bffFto3SSYpKcl5HhISYkaMGHHSY5GdnW0iIiJMQkKCOXbsmNO+bNkyI8lMmDCh0L48/PDDbuto3ry5adGixUm3YYwx+/fvNz4+PubKK680eXl5TvusWbOMJPPCCy84bUlJSUaS27E5meXLlxtJZtGiRcYYY3799VcjyXz00UcmMzPTeHp6muXLlxtjjNmyZYuRZB599FFjjDFvv/22kWQmT57sts7rr7/euFwus23bNqftZMd89OjRRpL57LPP3PY1JCTESDI7d+48Zf0F+1rUo0GDBk6/NWvWGEkmISHBZGdnO+19+vQxLpfLXHXVVW7rbdOmjYmJiXFrK1jvF1984bTt3r3b+Pn5mWuvvdZpGzRokImMjDS///672/I333yzCQkJccbpjBkzjCTz+uuvO32OHDli4uPj3d4HBWPsggsuMFlZWU7fuXPnGkmmQ4cOTtvOnTuNJLNgwQKnrbjjbsmSJUaSmTFjhtOWl5dnOnXqVGidp/PEE0+4/fx27dplPD09nbFT4JtvvjFeXl5Oe25uromLizMxMTHm0KFDbn3z8/NLvE8FxyMsLMz88ccfTvs777xjJJn33nvPaSsYSwUKPueGDx/uto2+ffsW+pxITEwsNF6KWmdxj8OmTZuMJPPGG28UWieAysdljQDKVUZGhiQpKCioWP2Tk5MlSWPHjnVrv/vuuyWp0L1p559/vtq0aeM8b926tSSpU6dOOvfccwu179ixo9A2/z6FecEZiezsbKWkpDjtfz/bcujQIaWnp+uSSy4pdAmiJHXo0EHnn3/+afb0r/u2PvvsM/3yyy9Fvv7FF19o//79Gj58uNu9Pt27d1fDhg2LvE9v6NChbs8vueSSIvf571JSUpSdna3Ro0e7nVUcMmSIgoODS30/YNu2beXh4eHcS1ZwBu6iiy5yzroVXNpY8N+C+82Sk5Pl6empUaNGua3z7rvvljFG77//vlt7Ucc8OTlZF198sVq1auW0hYeH65ZbbinRfixZskQffPCB22PBggWF+vXv39/tTEnr1q1ljNHAgQPd+rVu3Vp79uxRbm6uW3ubNm3UokUL5/m5556ra665RitXrlReXp6MMVqyZIl69OghY4x+//1359GlSxelp6c74zE5OVmRkZG6/vrrnfVVq1ZNt99+u9s2C8bY0KFD5ePj47QPGDCgRGdQTjfuVqxYIW9vbw0ZMsRp8/Dw0IgRI4q9jZNZunSp8vPzdeONN7odk9q1a+u8887TmjVrJEmbNm3Szp07NXr06EJnPYu6PLC476WbbrpJNWrUcOsnFf1ZU6Dgc+7E8V1w5rM0inscCn6uK1eu1NGjR0u9PQDlg8saAZSr4OBgSX/dX1Ucu3fvloeHR6GZAGvXrq3q1atr9+7dbu1/D2DS//3iceLlWAXthw4dcmv38PBQ3bp13drq168vSW7fg7Vs2TJNnjxZmzdvdrtvp6hf6v4+A+GpTJ06VYmJiYqOjlaLFi3UrVs39e/f36mnYF8bNGhQaNmGDRs6oaeAn5+fwsPD3dpq1KhRaJ9PdLLt+Pj4qG7duoWOeXFVr15djRs3dgtgzZs3d4Ju27Zt3V7z8fFxgtTu3bsVFRVVKNQ3atTIreYCRR3z3bt3O6H874o6nqdy6aWXFmtCkJKMxfz8fKWnpyssLMxpP++88wqts379+jp69KgOHDggDw8PHT58WHPnzj3pzKYFE7bs3r1b8fHxhcbniftecBxP3La3t3eh98XJFGfc7d69W5GRkapWrZpbv1PN+FlcP/74o4wxRR4/SU5g3r59uyQ5l4ieSkneSyf+3AuC2qnedwWfc/Xq1XNrL+nY/LviHoe4uDiNHTtW06dP18svv6xLLrlEPXv2VL9+/bikEbAA4QxAuQoODlZUVJS2bNlSouWK+4Wtnp6eJWo3J0wmURyffPKJevbsqUsvvVSzZ89WZGSkvL29tWDBAr3yyiuF+hf3nqYbb7xRl1xyid566y2tWrVKTzzxhP79739r6dKluuqqq0pc58n2uTK1b99ezz33nA4fPqx169a53XfYtm1bvfDCC8rJydHatWvVokWLUs8GWNL7yMpDeY/FgolM+vXrd9J7tU51D2B5qexxl5+fL5fLpffff7/IWkrzhdIl2aey/Kwpysk+C0+ccKUkx+HJJ5/UgAED9M4772jVqlUaNWqUpkyZok8//VR16tQpk7oBlA7hDEC5u/rqqzV37lxt2LDB7RLEosTExCg/P18//vijc5ZE+msihMOHDysmJqZMa8vPz9eOHTucs2WS9MMPP0iSM4nFkiVL5Ofnp5UrV8rX19fpV9SlbSUVGRmp4cOHa/jw4dq/f78uvPBCPfroo7rqqqucfU1LS1OnTp3clktLSyuzY/H37fz9bEl2drZ27typzp07l3rd7du315w5c5SSkqJNmzbp3nvvdV5r27atjh07puXLl2vHjh3q3bu3W00pKSnKzMx0O3v2/fffu9V8uv368ccfC7WnpaWVen/KU1G1/vDDD6pWrZpzFicoKEh5eXmn/ZnExMRoy5YtMsa4/XJ/4r4XHMcff/zRbYzl5ORo586datasWan358TtrFmzRkePHnU7e7Zt27YzXne9evVkjFFcXJzb+7iofpK0ZcuWMxrTZaHgc2779u1uZ8uKGps1atRwmzW1wIlnj4t7HAo0adJETZo00UMPPaT169erXbt2eu655zR58uSS7xCAMsM9ZwDK3X333aeAgAANHjxYv/32W6HXt2/f7kxl3a1bN0l/ffHs302fPl2Szng2s6LMmjXL+bcxRrNmzZK3t7cuv/xySX/9ZdzlchWaRvvtt98u9Tbz8vIKTVsdERGhqKgo57LJli1bKiIiQs8995zbpZTvv/++tm7dWmbHonPnzvLx8dEzzzzj9tf++fPnKz09/Yy2U3AP2fTp05WTk+N25iw2NlaRkZGaOnWqW1/pr3GQl5fn9rORpKeeekoul6tYZxa7deumTz/9VBs3bnTaDhw4oJdffrnU+1OeNmzY4HYP4549e/TOO+/oyiuvlKenpzw9PdW7d28tWbKkyDPRBw4ccP7drVs3/fLLL25f93D06NFCl0O2bNlS4eHheu6555Sdne20L1y4sMhAUFpdunRRTk6O5s2b57Tl5+fr2WefPeN1X3fddfL09NSkSZMKna0yxujgwYOSpAsvvFBxcXGaMWNGoX0rq7NcxVUwfp955hm39hM/96S/Qld6erq+/vprp+3XX38tNHNtcY9DRkZGofsdmzRpIg8Pj5N+1QKAisOZMwDlrl69enrllVd00003qVGjRurfv78SEhKUnZ2t9evX64033tCAAQMkSc2aNVNiYqLmzp2rw4cPq0OHDtq4caNefPFF9erVSx07dizT2vz8/LRixQolJiaqdevWev/997V8+XI98MADztmK7t27a/r06eratav69u2r/fv369lnn1V8fLzbL0wlkZmZqTp16uj6669Xs2bNFBgYqJSUFH3++ed68sknJf11j8i///1v3XbbberQoYP69OnjTKUfGxurMWPGlMkxCA8P1/33369Jkyapa9eu6tmzp9LS0jR79mxddNFFbl8UXVLnnnuuoqOjtWHDBsXGxioqKsrt9bZt22rJkiVyuVxq166d096jRw917NhRDz74oHbt2qVmzZpp1apVeueddzR69OhC9+oU5b777tOiRYvUtWtX3XXXXc5U+jExMSX6ub355ptFXhp3xRVXqFatWsVez+kkJCSoS5cublPpS9KkSZOcPo8//rjWrFmj1q1ba8iQITr//PP1xx9/6KuvvlJKSooz7f+QIUM0a9Ys9e/fX19++aUiIyO1aNGiQvd8eXt7a/LkybrjjjvUqVMn3XTTTdq5c6cWLFhQ7HvOiqNXr15q1aqV7r77bm3btk0NGzbUu+++69Rb3MuYi1KvXj1NnjxZ999/v3bt2qVevXopKChIO3fu1FtvvaXbb79d99xzjzw8PDRnzhz16NFDF1xwgW677TZFRkbq+++/17fffquVK1eW1e6e1gUXXKA+ffpo9uzZSk9PV9u2bbV69eoizyTefPPNGjdunK699lqNGjVKR48e1Zw5c1S/fn23MF/c4/Dhhx9q5MiRuuGGG1S/fn3l5uZq0aJFTvgHUMkqeHZIAP9gP/zwgxkyZIiJjY01Pj4+JigoyLRr187MnDnTHD9+3OmXk5NjJk2aZOLi4oy3t7eJjo42999/v1sfY/6aSr979+6FtiOp0BT1BdNeP/HEE05bYmKiCQgIMNu3bzdXXnmlqVatmqlVq5ZJSkpym1LeGGPmz59vzjvvPOPr62saNmxoFixYUGgq65Nt+++vFUyRnZWVZe69917TrFkzExQUZAICAkyzZs3M7NmzCy23ePFi07x5c+Pr62tCQ0PNLbfcYn7++We3PgX7cqKiajyZWbNmmYYNGxpvb29Tq1YtM2zYsEJTjpdkKv0Cffr0MZJM3759C702ffp0I8k0atSo0GuZmZlmzJgxJioqynh7e5vzzjvPPPHEE27Tnhtz6mP+9ddfmw4dOhg/Pz9zzjnnmEceecTMnz//jKfS19+moy+YSv/EqckXLFhgJJnPP/+8yPX+/RgW7MNLL73kjLPmzZu7ffVDgd9++82MGDHCREdHG29vb1O7dm1z+eWXm7lz57r12717t+nZs6epVq2aqVmzprnrrrvMihUrCn2lhDHGzJ4928TFxRlfX1/TsmVL8/HHH5sOHToUayr94o67AwcOmL59+5qgoCATEhJiBgwYYNatW2ckmddee63QOk7mxKn0CyxZssS0b9/eBAQEmICAANOwYUMzYsQIk5aW5tZv7dq15oorrnDed02bNjUzZ84s8T4V9ZlS4O/v9ZMdj2PHjplRo0aZsLAwExAQYHr06GH27NlTaFljjFm1apVJSEgwPj4+pkGDBuall1466Xv7dMdhx44dZuDAgaZevXrGz8/PhIaGmo4dO5qUlJRC6wJQ8VzGVPC5fACwxIABA/Tmm2/qzz//rOxSgH+kt99+W9dee63Wrl3rdub0n8zlcikpKUkTJ06s7FIAVALuOQMAAOXu2LFjbs/z8vI0c+ZMBQcH68ILL6ykqgDALtxzBgAAyt2dd96pY8eOqU2bNsrKytLSpUu1fv16PfbYY1Z8FQIA2IBwBgAAyl2nTp305JNPatmyZTp+/Lji4+M1c+ZMjRw5srJLAwBrcM8ZAAAAAFiAe84AAAAAwAKEMwAAAACwAPeclUB+fr5++eUXBQUFndEXZgIAAACo2owxyszMVFRUlDw8yuacF+GsBH755RdFR0dXdhkAAAAALLFnzx7VqVOnTNZFOCuBoKAgSdLOnTsVGhpaydXgbJaTk6NVq1bpyiuvlLe3d2WXg7MYYw0VhbGGisJYQ0X5448/FBcX52SEskA4K4GCSxmDgoIUHBxcydXgbJaTk6Nq1aopODiY/7GgXDHWUFEYa6gojDVUlJycHEkq09udmBAEAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAt4VXYBVdGzW/6QT7Cp7DJwFvPIz1UDSU99fVD5HrxNUX4Ya6go5T3WxjevWebrBICKxpkzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAAC5QonA0YMEAul6vQY9u2baUuIDU1VS6XS4cPH3baitrG3x8TJ04s9fZ27doll8ulzZs3l3odAAAAAFDWvEq6QNeuXbVgwQK3tvDw8DIrSJJ+/fVX59+LFy/WhAkTlJaW5rQFBgaW6fYAAAAAoLKV+LJGX19f1a5d2+3x9NNPq0mTJgoICFB0dLSGDx+uP//801lm9+7d6tGjh2rUqKGAgAA1btxYycnJ2rVrlzp27ChJqlGjhlwulwYMGOC27pCQELlcLre21157TY0aNZKfn58aNmyo2bNnO9saOHCgmjZtqqysLElSdna2mjdvrv79+0uS4uLiJEnNmzeXy+XSZZddVuqDBwAAAABlpcRnzori4eGhZ555RnFxcdqxY4eGDx+u++67zwlNI0aMUHZ2tj7++GMFBATou+++U2BgoKKjo7VkyRL17t1baWlpCg4Olr+//ym39fLLL2vChAmaNWuWmjdvrk2bNmnIkCEKCAhQYmKinnnmGTVr1kzjx4/XU089pQcffFCHDx/WrFmzJEkbN25Uq1atlJKSosaNG8vHx+ek28rKynJCniRlZGSUwdECAAAAgMJKHM6WLVvmdlnhVVddpTfeeMN5Hhsbq8mTJ2vo0KFOOPvpp5/Uu3dvNWnSRJJUt25dp39oaKgkKSIiQtWrVz/t9pOSkvTkk0/quuuuk/TXmbDvvvtOzz//vBITExUYGKiXXnpJHTp0UFBQkGbMmKE1a9YoODhY0v9dghkWFqbatWufcltTpkzRpEmTTlsTAAAAAJypEoezjh07as6cOc7zgIAApaSkaMqUKfr++++VkZGh3NxcHT9+XEePHlW1atU0atQoDRs2TKtWrVLnzp3Vu3dvNW3atMTFHjlyRNu3b9egQYM0ZMgQpz03N1chISHO8zZt2uiee+7RI488onHjxql9+/Yl3pYk3X///Ro7dqzzPCMjQ9HR0aVaFwAAAACcSonvOQsICFB8fLzzyMrK0tVXX62mTZtqyZIl+vLLL/Xss89K+ut+L0kaPHiwduzYoVtvvVXffPONWrZsqZkzZ5a42IL72ObNm6fNmzc7jy1btujTTz91+uXn52vdunXy9PQ8o5kkfX19FRwc7PYAAAAAgPJwxt9z9uWXXyo/P19PPvmkLr74YtWvX1+//PJLoX7R0dEaOnSoli5dqrvvvlvz5s2TJOeer7y8vNNuq1atWoqKitKOHTvcAmJ8fLwz0YckPfHEE/r+++/10UcfacWKFW6zS5ZkewAAAABQUc54QpD4+Hjl5ORo5syZ6tGjh9atW6fnnnvOrc/o0aN11VVXqX79+jp06JDWrFmjRo0aSZJiYmLkcrm0bNkydevWTf7+/qecKn/SpEkaNWqUQkJC1LVrV2VlZemLL77QoUOHNHbsWG3atEkTJkzQm2++qXbt2mn69Om666671KFDB9WtW1cRERHy9/fXihUrVKdOHfn5+bldEgkAAAAAleGMz5w1a9ZM06dP17///W8lJCTo5Zdf1pQpU9z65OXlacSIEWrUqJG6du2q+vXrO5OFnHPOOZo0aZLGjx+vWrVqaeTIkafc3uDBg/Wf//xHCxYsUJMmTdShQwctXLhQcXFxOn78uPr166cBAwaoR48ekqTbb79dHTt21K233qq8vDx5eXnpmWee0fPPP6+oqChdc801Z3oIAAAAAOCMuYwxprKLqCoyMjIUEhKiSak/yCe4RmWXg7OYR36uGvz8mdLqtFa+R5l84wVQJMYaKkp5j7XxzWuW+TpRNeXk5Cg5OVndunWTt7d3ZZeDs9jBgwdVs2ZNpaenl9ncFGd85gwAAAAAcOYIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFvCq7gKpoREKowsLCKrsMnMVycnKU/LM0pmmYvL29K7scnMUYa6gojDUAOD3OnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAW8KruAqujZLX/IJ9hUdhk4i3nk56qBpKe+Pqh8D96mKD+MNVQUxlrlGt+8ZmWXAKAYOHMGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABggXIPZwcOHNCwYcN07rnnytfXV7Vr11aXLl20bt06SVJsbKxcLpdcLpc8PT0VFRWlQYMG6dChQ846UlNTnT4nPvbt2ydJmjhxott6oqOjdfvtt+uPP/445fIFj9TU1PI+FAAAAABwUl7lvYHevXsrOztbL774ourWravffvtNq1ev1sGDB50+Dz/8sIYMGaK8vDz98MMPuv322zVq1CgtWrTIbV1paWkKDg52a4uIiHD+3bhxY6WkpCgvL09bt27VwIEDlZ6erkWLFunXX391+t11113KyMjQggULnLbQ0NCy3nUAAAAAKLZyDWeHDx/WJ598otTUVHXo0EGSFBMTo1atWrn1CwoKUu3atSVJ55xzjhITE/Xqq68WWl9ERISqV69+0u15eXm5reeGG27QggUL5OPj47RLkr+/v7KystzaAAAAAKAyletljYGBgQoMDNTbb7+trKysYi2zd+9evffee2rduvUZbXvXrl1auXKlfHx8Sr2OrKwsZWRkuD0AAAAAoDyUazjz8vLSwoUL9eKLL6p69epq166dHnjgAX399ddu/caNG6fAwED5+/urTp06crlcmj59eqH11alTxwl8gYGBaty4sdvr33zzjbOeuLg4ffvttxo3blyp658yZYpCQkKcR3R0dKnXBQAAAACnUu4TgvTu3Vu//PKL3n33XXXt2lWpqam68MILtXDhQqfPvffeq82bN+vrr7/W6tWrJUndu3dXXl6e27o++eQTbd682XkkJye7vd6gQQNt3rxZn3/+ucaNG6cuXbrozjvvLHXt999/v9LT053Hnj17Sr0uAAAAADiVCplK38/PT1dccYX+9a9/af369RowYICSkpKc12vWrKn4+Hidd9556tSpk2bMmKH169drzZo1buuJi4tTfHy884iJiXF73cfHR/Hx8UpISNDjjz8uT09PTZo0qdR1+/r6Kjg42O0BAAAAAOWhUr7n7Pzzz9eRI0dO+rqnp6ck6dixY2e0nYceekjTpk3TL7/8ckbrAQAAAIDyVq6zNR48eFA33HCDBg4cqKZNmyooKEhffPGFpk6dqmuuucbpl5mZqX379skYoz179ui+++5TeHi42rZt67a+/fv36/jx425tYWFh8vb2LnL7bdq0UdOmTfXYY49p1qxZZb+DAAAAAFBGyjWcBQYGqnXr1nrqqae0fft25eTkKDo6WkOGDNEDDzzg9JswYYImTJggSQoPD9dFF12kVatWKSwszG19DRo0KLSNDRs26OKLLz5pDWPGjNGAAQM0btw4JvQAAAAAYC2XMcZUdhFVRUZGhkJCQjQp9Qf5BNeo7HJwFvPIz1WDnz9TWp3Wyvco9++Kxz8YYw0VhbFWucY3r1nZJVSYnJwcJScnq1u3bie9ugooCwcPHlTNmjWVnp5eZnNTVMo9ZwAAAAAAd4QzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAJelV1AVTQiIVRhYWGVXQbOYjk5OUr+WRrTNEze3t6VXQ7OYow1VBTGGgCcHmfOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAl6VXUBV9OyWP+QTbCq7DJzFPPJz1UDSU18fVL4Hb1OUH8YaKgpjDRWlJGNtfPOaFVMUUEycOQMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALBAuYUzl8t1ysfEiRO1a9euIl/r16/fSdebmpoql8ulw4cPuz13uVzy8PBQSEiImjdvrvvuu0+//vqr27ITJ04scnspKSnldRgAAAAAoFi8ymvFfw9Gixcv1oQJE5SWlua0BQYG6vfff5ckpaSkqHHjxs5r/v7+Jd5eWlqagoODlZGRoa+++kpTp07V/PnzlZqaqiZNmjj9GjduXCiMhYaGlnh7AAAAAFCWyi2c1a5d2/l3SEiIXC6XW5skJ5yFhYUVeq2kIiIiVL16ddWuXVv169fXNddco+bNm2vYsGFau3at08/Ly+uMtwUAAAAAZe2svefM399fQ4cO1bp167R///5SrSMrK0sZGRluDwAAAAAoD1aEs7Zt2yowMNB5bNq0qUzW27BhQ0nSrl27nLZvvvnGbVutWrU66fJTpkxRSEiI84iOji6TugAAAADgROV2WWNJLF68WI0aNXKeF4Sgxo0ba/fu3ZKkSy65RO+//36J1muMkfTX5CQFGjRooHfffdd57uvre9Ll77//fo0dO9Z5npGRQUADAAAAUC6sCGfR0dGKj48v1J6cnKycnBxJpZskZOvWrZKk2NhYp83Hx6fIbRXF19f3lOENAAAAAMqKFeHsZGJiYkq97LFjxzR37lxdeumlCg8PL8OqAAAAAKDsWR3OSmL//v06fvy4MjMz9eWXX2rq1Kn6/ffftXTp0souDQAAAABO66wJZw0aNJDL5VJgYKDq1q2rK6+8UmPHjmXafAAAAABVgssUzJqB08rIyFBISIgmpf4gn+AalV0OzmIe+blq8PNnSqvTWvkeZ83fUGAhxhoqCmMNFaUkY21885oVVBXORgcPHlTNmjWVnp6u4ODgMlmnFVPpAwAAAMA/HeEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsIBXZRdQFY1ICFVYWFhll4GzWE5OjpJ/lsY0DZO3t3dll4OzGGMNFYWxhorCWENVxpkzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAACxDOAAAAAMAChDMAAAAAsADhDAAAAAAsQDgDAAAAAAsQzgAAAADAAoQzAAAAALAA4QwAAAAALEA4AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAOAMAAAAAC3hVdgFViTFGkpSZmSlvb+9KrgZns5ycHB09elQZGRmMNZQrxhoqCmMNFYWxhoqSmZkp6f8yQlkgnJXAwYMHJUlxcXGVXAkAAAAAGxw8eFAhISFlsi7CWQmEhoZKkn766acy+wEARcnIyFB0dLT27Nmj4ODgyi4HZzHGGioKYw0VhbGGipKenq5zzz3XyQhlgXBWAh4ef92iFxISwpsdFSI4OJixhgrBWENFYayhojDWUFEKMkKZrKvM1gQAAAAAKDXCGQAAAABYgHBWAr6+vkpKSpKvr29ll4KzHGMNFYWxhorCWENFYayhopTHWHOZspz7EQAAAABQKpw5AwAAAAALEM4AAAAAwAKEMwAAAACwAOEMAAAAACxAODvBs88+q9jYWPn5+al169bauHHjKfu/8cYbatiwofz8/NSkSRMlJydXUKWo6koy1ubNm6dLLrlENWrUUI0aNdS5c+fTjk2gQEk/1wq89tprcrlc6tWrV/kWiLNGScfa4cOHNWLECEVGRsrX11f169fn/6MolpKOtRkzZqhBgwby9/dXdHS0xowZo+PHj1dQtaiKPv74Y/Xo0UNRUVFyuVx6++23T7tMamqqLrzwQvn6+io+Pl4LFy4s8XYJZ3+zePFijR07VklJSfrqq6/UrFkzdenSRfv37y+y//r169WnTx8NGjRImzZtUq9evdSrVy9t2bKlgitHVVPSsZaamqo+ffpozZo12rBhg6Kjo3XllVdq7969FVw5qpqSjrUCu3bt0j333KNLLrmkgipFVVfSsZadna0rrrhCu3bt0ptvvqm0tDTNmzdP55xzTgVXjqqmpGPtlVde0fjx45WUlKStW7dq/vz5Wrx4sR544IEKrhxVyZEjR9SsWTM9++yzxeq/c+dOde/eXR07dtTmzZs1evRoDR48WCtXrizZhg0crVq1MiNGjHCe5+XlmaioKDNlypQi+994442me/fubm2tW7c2d9xxR7nWiaqvpGPtRLm5uSYoKMi8+OKL5VUizhKlGWu5ubmmbdu25j//+Y9JTEw011xzTQVUiqqupGNtzpw5pm7duiY7O7uiSsRZoqRjbcSIEaZTp05ubWPHjjXt2rUr1zpx9pBk3nrrrVP2ue+++0zjxo3d2m666SbTpUuXEm2LM2f/X3Z2tr788kt17tzZafPw8FDnzp21YcOGIpfZsGGDW39J6tKly0n7A1LpxtqJjh49qpycHIWGhpZXmTgLlHasPfzww4qIiNCgQYMqokycBUoz1t599121adNGI0aMUK1atZSQkKDHHntMeXl5FVU2qqDSjLW2bdvqyy+/dC593LFjh5KTk9WtW7cKqRn/DGWVC7zKsqiq7Pfff1deXp5q1arl1l6rVi19//33RS6zb9++Ivvv27ev3OpE1VeasXaicePGKSoqqtCHAPB3pRlra9eu1fz587V58+YKqBBni9KMtR07dujDDz/ULbfcouTkZG3btk3Dhw9XTk6OkpKSKqJsVEGlGWt9+/bV77//rvbt28sYo9zcXA0dOpTLGlGmTpYLMjIydOzYMfn7+xdrPZw5A6qYxx9/XK+99preeust+fn5VXY5OItkZmbq1ltv1bx581SzZs3KLgdnufz8fEVERGju3Llq0aKFbrrpJj344IN67rnnKrs0nGVSU1P12GOPafbs2frqq6+0dOlSLV++XI888khllwYUwpmz/69mzZry9PTUb7/95tb+22+/qXbt2kUuU7t27RL1B6TSjbUC06ZN0+OPP66UlBQ1bdq0PMvEWaCkY2379u3atWuXevTo4bTl5+dLkry8vJSWlqZ69eqVb9GokkrzuRYZGSlvb295eno6bY0aNdK+ffuUnZ0tHx+fcq0ZVVNpxtq//vUv3XrrrRo8eLAkqUmTJjpy5Ihuv/12Pfjgg/Lw4FwFztzJckFwcHCxz5pJnDlz+Pj4qEWLFlq9erXTlp+fr9WrV6tNmzZFLtOmTRu3/pL0wQcfnLQ/IJVurEnS1KlT9cgjj2jFihVq2bJlRZSKKq6kY61hw4b65ptvtHnzZufRs2dPZ+ap6OjoiiwfVUhpPtfatWunbdu2OX8AkKQffvhBkZGRBDOcVGnG2tGjRwsFsII/Cvw11wNw5sosF5RsrpKz22uvvWZ8fX3NwoULzXfffWduv/12U716dbNv3z5jjDG33nqrGT9+vNN/3bp1xsvLy0ybNs1s3brVJCUlGW9vb/PNN99U1i6giijpWHv88ceNj4+PefPNN82vv/7qPDIzMytrF1BFlHSsnYjZGlFcJR1rP/30kwkKCjIjR440aWlpZtmyZSYiIsJMnjy5snYBVURJx1pSUpIJCgoyr776qtmxY4dZtWqVqVevnrnxxhsraxdQBWRmZppNmzaZTZs2GUlm+vTpZtOmTWb37t3GGGPGjx9vbr31Vqf/jh07TLVq1cy9995rtm7dap599lnj6elpVqxYUaLtEs5OMHPmTHPuuecaHx8f06pVK/Ppp586r3Xo0MEkJia69X/99ddN/fr1jY+Pj2ncuLFZvnx5BVeMqqokYy0mJsZIKvRISkqq+MJR5ZT0c+3vCGcoiZKOtfXr15vWrVsbX19fU7duXfPoo4+a3NzcCq4aVVFJxlpOTo6ZOHGiqVevnvHz8zPR0dFm+PDh5tChQxVfOKqMNWvWFPm7V8HYSkxMNB06dCi0zAUXXGB8fHxM3bp1zYIFC0q8XZcxnM8FAAAAgMrGPWcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABQhnAAAAAGABwhkAAAAAWIBwBgAAAAAWIJwBAAAAgAUIZwAAAABgAcIZAKDK27Bhgzw9PdW9e/fKLgUAgFJzGWNMZRcBAMCZGDx4sAIDAzV//nylpaUpKiqqUurIzs6Wj49PpWwbAFD1ceYMAFCl/fnnn1q8eLGGDRum7t27a+HChW6vv/fee7rooovk5+enmjVr6tprr3Vey8rK0rhx4xQdHS1fX1/Fx8dr/vz5kqSFCxeqevXqbut6++235XK5nOcTJ07UBRdcoP/85z+Ki4uTn5+fJGnFihVq3769qlevrrCwMF199dXavn2727p+/vln9enTR6GhoQoICFDLli312WefadeuXfLw8NAXX3zh1n/GjBmKiYlRfn7+mR4yAIClCGcAgCrt9ddfV8OGDdWgQQP169dPL7zwggouClm+fLmuvfZadevWTZs2bdLq1avVqlUrZ9n+/fvr1Vdf1TPPPKOtW7fq+eefV2BgYIm2v23bNi1ZskRLly7V5s2bJUlHjhzR2LFj9cUXX2j16tXy8PDQtdde6wSrP//8Ux06dNDevXv17rvv6n//+5/uu+8+5efnKzY2Vp07d9aCBQvctrNgwQINGDBAHh78rxsAzlZelV0AAABnYv78+erXr58kqWvXrkpPT9dHH32kyy67TI8++qhuvvlmTZo0yenfrFkzSdIPP/yg119/XR988IE6d+4sSapbt26Jt5+dna3//ve/Cg8Pd9p69+7t1ueFF15QeHi4vvvuOyUkJOiVV17RgQMH9Pnnnys0NFSSFB8f7/QfPHiwhg4dqunTp8vX11dfffWVvvnmG73zzjslrg8AUHXw5zcAQJWVlpamjRs3qk+fPpIkLy8v3XTTTc6liZs3b9bll19e5LKbN2+Wp6enOnTocEY1xMTEuAUzSfrxxx/Vp08f1a1bV8HBwYqNjZUk/fTTT862mzdv7gSzE/Xq1Uuenp566623JP11iWXHjh2d9QAAzk6cOQMAVFnz589Xbm6u2wQgxhj5+vpq1qxZ8vf3P+myp3pNkjw8PHTinFk5OTmF+gUEBBRq69Gjh2JiYjRv3jxFRUUpPz9fCQkJys7OLta2fXx81L9/fy1YsEDXXXedXnnlFT399NOnXAYAUPVx5gwAUCXl5ubqv//9r5588klt3rzZefzvf/9TVFSUXn31VTVt2lSrV68ucvkmTZooPz9fH330UZGvh4eHKzMzU0eOHHHaCu4pO5WDBw8qLS1NDz30kC6//HI1atRIhw4dcuvTtGlTbd68WX/88cdJ1zN48GClpKRo9uzZys3N1XXXXXfabQMAqjbOnAEAqqRly5bp0KFDGjRokEJCQtxe6927t+bPn68nnnhCl19+uerVq6ebb75Zubm5Sk5O1rhx4xQbG6vExEQNHDhQzzzzjJo1a6bdu3dr//79uvHGG9W6dWtVq1ZNDzzwgEaNGqXPPvus0EyQRalRo4bCwsI0d+5cRUZG6qefftL48ePd+vTp00ePPfaYevXqpSlTpigyMlKbNm1SVFSU2rRpI0lq1KiRLr74Yo0bN04DBw487dk2AEDVx5kzAECVNH/+fHXu3LlQMJP+CmdffPGFQkND9cYbb+jdd9/VBRdcoE6dOmnjxo1Ovzlz5uj666/X8OHD1bBhQw0ZMsQ5UxYaGqqXXnpJycnJatKkiV599VVNnDjxtHV5eHjotdde05dffqmEhASNGTNGTzzxhFsfHx8frVq1ShEREerWrZuaNGmixx9/XJ6enm79Bg0apOzsbA0cOLAURwgAUNXwJdQAAFjqkUce0RtvvKGvv/66sksBAFQAzpwBAGCZP//8U1u2bNGsWbN05513VnY5AIAKQjgDAMAyI0eOVIsWLXTZZZdxSSMA/INwWSMAAAAAWIAzZwAAAABgAcIZAAAAAFiAcAYAAAAAFiCcAQAAAIAFCGcAAAAAYAHCGQAAAABYgHAGAAAAABYgnAEAAACABf4fHkvFGJJ55gwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for plotting\n",
    "methods = list(results.keys())\n",
    "accuracies = [result[0] for result in results.values()]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(methods, accuracies, color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Comparison of Word Embedding Techniques')\n",
    "plt.xlim(0, 1)  # Set limits to 0-1 for better visibility\n",
    "plt.grid(axis='x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Nettoyage et prétraitement du texte\n",
    "# Tu peux appliquer ici des étapes de nettoyage comme la suppression de la ponctuation, la conversion en minuscules, etc.\n",
    "\n",
    "# 2. Tokenisation\n",
    "texts=list(df['filtered_text'])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "labels=label_encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séquences avec padding :\n",
      "[[   41   238  3403 ...     0     0     0]\n",
      " [ 7746    33   169 ...     0     0     0]\n",
      " [ 3718     7     4 ...     0     0     0]\n",
      " ...\n",
      " [  198   171     3 ...     0     0     0]\n",
      " [11447     8   132 ...     0     0     0]\n",
      " [ 4784     1   589 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Padding\n",
    "# Ajuster la longueur des séquences pour qu'elles soient de la même longueur\n",
    "X = pad_sequences(sequences, padding='post')  # Ajout de zéros à la fin pour compléter les séquences\n",
    "# 4. Diviser les données en entraînement et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "# Afficher le résultat\n",
    "print(\"Séquences avec padding :\")\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - accuracy: 0.4651 - loss: 0.6955 - val_accuracy: 0.5025 - val_loss: 0.6937\n",
      "Epoch 2/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.4802 - loss: 0.6950 - val_accuracy: 0.5025 - val_loss: 0.6931\n",
      "Epoch 3/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.5153 - loss: 0.6934 - val_accuracy: 0.4975 - val_loss: 0.6936\n",
      "Epoch 4/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.4815 - loss: 0.6938 - val_accuracy: 0.4975 - val_loss: 0.6932\n",
      "Epoch 5/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.4892 - loss: 0.6942 - val_accuracy: 0.4975 - val_loss: 0.6934\n",
      "Epoch 6/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.5100 - loss: 0.6933 - val_accuracy: 0.4975 - val_loss: 0.6934\n",
      "Epoch 7/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.4870 - loss: 0.6944 - val_accuracy: 0.5025 - val_loss: 0.6938\n",
      "Epoch 8/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.4958 - loss: 0.6939 - val_accuracy: 0.4975 - val_loss: 0.6937\n",
      "Epoch 9/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.4979 - loss: 0.6965 - val_accuracy: 0.5025 - val_loss: 0.6932\n",
      "Epoch 10/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.4894 - loss: 0.6933 - val_accuracy: 0.5025 - val_loss: 0.6933\n",
      "Epoch 11/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4567 - loss: 0.6956 - val_accuracy: 0.4975 - val_loss: 0.6933\n",
      "Epoch 12/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - accuracy: 0.4939 - loss: 0.6939 - val_accuracy: 0.4975 - val_loss: 0.6933\n",
      "Epoch 13/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.4874 - loss: 0.6936 - val_accuracy: 0.5025 - val_loss: 0.6931\n",
      "Epoch 14/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.4615 - loss: 0.6942 - val_accuracy: 0.5025 - val_loss: 0.6931\n",
      "Epoch 15/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.5117 - loss: 0.6935 - val_accuracy: 0.4975 - val_loss: 0.6938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27c1e7bb910>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuite, tu peux définir ton modèle LSTM comme suit :\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=X_train.shape[1]),  # Embedding des mots\n",
    "    LSTM(128, return_sequences=False),  # LSTM\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Classification binaire\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=X_train.shape[1]),  # Embedding des mots\n",
    "    LSTM(128, return_sequences=False),  # LSTM\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Classification binaire\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
